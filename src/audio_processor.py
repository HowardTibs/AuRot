"""
Audio processing module for Whisper AI transcription
WITH GPU ACCELERATION and optimizations for faster processing
Enhanced with dual audio support for Reddit integration
FIXED VERSION - All errors resolved
UPDATED: Enhanced dead air support with 3.5-second ending silence
FIXED: Proper audio composition with exact timing for video synchronization
CRITICAL FIX: Added validation to prevent script words extending beyond actual audio duration
"""

import whisper
import soundfile as sf
import tempfile
import logging
import threading
import torch
import warnings
import time
import numpy as np
from typing import Dict, List, Optional, Tuple

# Suppress specific Triton warnings if needed
warnings.filterwarnings("ignore", message=".*Failed to launch Triton kernels.*")

logger = logging.getLogger(__name__)

class AudioProcessor:
    """FIXED: Handles all audio processing and transcription tasks with GPU optimizations + dual audio support + dead air + Script validation"""
    
    def __init__(self, model_size: str = "base"):
        """Initialize with Whisper model and GPU detection"""
        self.model_size = model_size
        self.whisper_model = None
        self.model_lock = threading.Lock()  # Thread safety for model access
        self.device = self._detect_device()
        self.load_whisper_model()
        
        # Dead air configuration - EXACTLY 3.5 seconds
        self.default_ending_silence = 3.5  # Default 3.5 seconds of dead air
    
    def _detect_device(self) -> str:
        """Detect and log the best available device"""
        if torch.cuda.is_available():
            device = "cuda"
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            logger.info(f"üöÄ GPU Detected: {gpu_name} ({gpu_memory:.1f}GB)")
            logger.info(f"‚úÖ Using CUDA acceleration")
        else:
            device = "cpu"
            logger.info("‚ö†Ô∏è No CUDA GPU detected, using CPU")
        
        return device
    
    def load_whisper_model(self):
        """Load Whisper model for transcription with GPU support"""
        try:
            logger.info(f"Loading Whisper model: {self.model_size} on {self.device}")
            with self.model_lock:
                # Explicitly specify device for Whisper
                self.whisper_model = whisper.load_model(self.model_size, device=self.device)
            
            if self.device == "cuda":
                logger.info("üéØ Whisper model loaded on GPU - expect 5-10x faster transcription!")
            else:
                logger.info("üìä Whisper model loaded on CPU")
                
        except Exception as e:
            logger.error(f"Failed to load Whisper model: {e}")
            # Fallback to CPU if GPU fails
            if self.device == "cuda":
                logger.warning("GPU failed, falling back to CPU...")
                self.device = "cpu"
                self.whisper_model = whisper.load_model(self.model_size, device="cpu")
            else:
                raise Exception(f"Could not load Whisper model: {e}")
    
    def get_audio_duration(self, audio_path: str) -> float:
        """Get duration of audio file without full processing"""
        try:
            audio_data, sample_rate = sf.read(audio_path)
            duration = len(audio_data) / sample_rate
            logger.info(f"Audio duration: {duration:.2f}s ({audio_path})")
            return duration
        except Exception as e:
            logger.error(f"Failed to get audio duration: {e}")
            return 0.0
    
    def validate_dual_audio_files(self, title_audio_path: str, main_audio_path: str) -> Tuple[bool, str]:
        """Validate both audio files for dual audio system"""
        try:
            # Validate title audio
            if not self.validate_audio_file(title_audio_path):
                return False, "‚ùå Invalid title audio file"
            
            # Validate main audio
            if not self.validate_audio_file(main_audio_path):
                return False, "‚ùå Invalid main audio file"
            
            # Get durations
            title_duration = self.get_audio_duration(title_audio_path)
            main_duration = self.get_audio_duration(main_audio_path)
            
            # Check reasonable durations
            if title_duration < 0.5:
                return False, "‚ùå Title audio too short (minimum 0.5s)"
            
            if main_duration < 1.0:
                return False, "‚ùå Main audio too short (minimum 1s)"
            
            if title_duration > 30.0:
                return False, "‚ùå Title audio too long (maximum 30s)"
            
            if main_duration > 300.0:
                return False, "‚ùå Main audio too long (maximum 5 minutes)"
            
            logger.info(f"‚úÖ Dual audio validation passed - Title: {title_duration:.2f}s, Main: {main_duration:.2f}s")
            return True, f"‚úÖ Audio files validated - Title: {title_duration:.2f}s, Main: {main_duration:.2f}s"
            
        except Exception as e:
            logger.error(f"Dual audio validation failed: {e}")
            return False, f"‚ùå Validation error: {str(e)}"
    
    def process_dual_audio_system(self, title_audio_path: str, main_audio_path: str, ending_silence: float = None) -> Dict:
        """
        FIXED: Process both audio files for Reddit integration system with EXACT timing calculations + Script validation
        
        Args:
            title_audio_path: Path to title audio
            main_audio_path: Path to main audio  
            ending_silence: Duration of ending silence for dead air (default 3.5s)
            
        Returns:
            Dictionary with EXACT timing information including dead air + script safety info
        """
        try:
            # Use default ending silence if not specified
            if ending_silence is None:
                ending_silence = self.default_ending_silence
            
            logger.info(f"üéµ Processing dual audio system with SCRIPT VALIDATION (title + main + {ending_silence:.1f}s dead air)")
            
            # Validate both files first
            is_valid, validation_message = self.validate_dual_audio_files(title_audio_path, main_audio_path)
            if not is_valid:
                return {
                    'success': False,
                    'error': validation_message,
                    'title_duration': 0.0,
                    'main_duration': 0.0,
                    'total_duration': 0.0,
                    'ending_silence': ending_silence
                }
            
            # Get EXACT durations
            title_duration = self.get_audio_duration(title_audio_path)
            
            # Transcribe main audio only with enhanced validation
            main_transcription = self.transcribe_with_timestamps_and_validation(main_audio_path)
            
            if not main_transcription['words']:
                return {
                    'success': False,
                    'error': '‚ùå Failed to transcribe main audio',
                    'title_duration': title_duration,
                    'main_duration': 0.0,
                    'total_duration': title_duration + 1.0 + ending_silence,
                    'ending_silence': ending_silence
                }
            
            main_duration = main_transcription['duration']
            delay_duration = 1.0  # EXACTLY 1 second delay
            reddit_display_duration = title_duration + delay_duration
            
            # FIXED: Calculate EXACT durations for video synchronization
            audio_content_duration = reddit_display_duration + main_duration
            total_duration = audio_content_duration + ending_silence
            
            # NEW: Calculate safe audio bounds for script validation
            safe_main_audio_end = main_duration  # End of actual main audio content
            safe_total_audio_end = audio_content_duration  # End of all audio content (before dead air)
            
            result = {
                'success': True,
                'title_duration': title_duration,
                'main_duration': main_duration,
                'delay_duration': delay_duration,
                'reddit_display_duration': reddit_display_duration,
                'ending_silence': ending_silence,
                'audio_content_duration': audio_content_duration,  # Duration without dead air
                'total_duration': total_duration,  # Duration including dead air
                'main_transcription': main_transcription,
                'title_audio_path': title_audio_path,
                'main_audio_path': main_audio_path,
                'dead_air_start': audio_content_duration,  # When dead air begins
                # NEW: Safe bounds for script validation
                'safe_main_audio_end': safe_main_audio_end,  # End of main audio only
                'safe_total_audio_end': safe_total_audio_end,  # End of all audio content
                'script_validation_bounds': {
                    'main_audio_end': safe_main_audio_end,
                    'total_audio_end': safe_total_audio_end,
                    'dead_air_start': audio_content_duration,
                    'tolerance': 0.1  # Small tolerance for timing imprecision
                },
                'phases': {
                    'title_phase': {'start': 0.0, 'end': title_duration},
                    'delay_phase': {'start': title_duration, 'end': reddit_display_duration},
                    'main_phase': {'start': reddit_display_duration, 'end': audio_content_duration},
                    'dead_air_phase': {'start': audio_content_duration, 'end': total_duration}
                }
            }
            
            logger.info(f"‚úÖ Dual audio processing complete with SCRIPT VALIDATION bounds:")
            logger.info(f"  ‚Ä¢ Title: {title_duration:.2f}s")
            logger.info(f"  ‚Ä¢ Delay: {delay_duration:.2f}s") 
            logger.info(f"  ‚Ä¢ Main: {main_duration:.2f}s")
            logger.info(f"  ‚Ä¢ Audio content ends: {audio_content_duration:.2f}s")
            logger.info(f"  ‚Ä¢ Dead air: {ending_silence:.2f}s")
            logger.info(f"  ‚Ä¢ Total duration: {total_duration:.2f}s")
            logger.info(f"  üõ°Ô∏è Script validation bounds: main={safe_main_audio_end:.2f}s, total={safe_total_audio_end:.2f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"Dual audio processing failed: {e}")
            return {
                'success': False,
                'error': f'‚ùå Processing error: {str(e)}',
                'title_duration': 0.0,
                'main_duration': 0.0,
                'total_duration': 0.0,
                'ending_silence': ending_silence or self.default_ending_silence
            }
    
    def trim_audio_to_duration(self, audio_path: str, max_duration: float = 90.0) -> str:
        """Trim audio to fit within reel duration limits"""
        try:
            audio_data, sample_rate = sf.read(audio_path)
            max_samples = int(max_duration * sample_rate)
            
            if len(audio_data) > max_samples:
                logger.info(f"Trimming audio from {len(audio_data)/sample_rate:.2f}s to {max_duration}s")
                trimmed_audio = audio_data[:max_samples]
                trimmed_path = tempfile.mktemp(suffix='.wav')
                sf.write(trimmed_path, trimmed_audio, sample_rate)
                return trimmed_path
            else:
                logger.info("Audio duration is within limits, no trimming needed")
                return audio_path
                
        except Exception as e:
            logger.error(f"Audio trimming failed: {e}")
            return audio_path
    
    def transcribe_with_timestamps(self, audio_path: str) -> Dict:
        """Transcribe audio and extract word-level timestamps with GPU acceleration"""
        try:
            logger.info(f"üé§ Starting audio transcription on {self.device.upper()}...")
            
            # Show GPU memory usage if using CUDA
            if self.device == "cuda":
                gpu_memory_before = torch.cuda.memory_allocated(0) / 1024**2
                logger.info(f"GPU Memory before: {gpu_memory_before:.1f}MB")
            
            start_time = time.time()
            
            with self.model_lock:  # Thread-safe model access
                result = self.whisper_model.transcribe(
                    audio_path,
                    word_timestamps=True,
                    verbose=False,
                    language="en"
                )
            
            transcription_time = time.time() - start_time
            
            # Show performance stats
            if self.device == "cuda":
                gpu_memory_after = torch.cuda.memory_allocated(0) / 1024**2
                logger.info(f"GPU Memory after: {gpu_memory_after:.1f}MB")
                logger.info(f"‚ö° GPU Transcription completed in {transcription_time:.2f}s")
            else:
                logger.info(f"üíª CPU Transcription completed in {transcription_time:.2f}s")
            
            words_with_timing = []
            full_text = ""
            
            for segment in result.get('segments', []):
                if 'words' in segment and segment['words']:
                    for word_data in segment['words']:
                        word_info = {
                            'text': word_data.get('word', '').strip(),
                            'start': word_data.get('start', 0),
                            'end': word_data.get('end', 0),
                            'confidence': word_data.get('probability', 0.9)
                        }
                        words_with_timing.append(word_info)
                        full_text += word_info['text'] + " "
            
            total_duration = result.get('segments', [{}])[-1].get('end', 0) if result.get('segments') else 0
            
            transcription_result = {
                'text': full_text.strip(),
                'words': words_with_timing,
                'duration': total_duration,
                'language': result.get('language', 'en'),
                'segments_count': len(result.get('segments', [])),
                'device_used': self.device,
                'transcription_time': transcription_time
            }
            
            logger.info(f"‚úÖ Transcription complete: {len(words_with_timing)} words, {total_duration:.2f}s duration")
            return transcription_result
            
        except Exception as e:
            logger.error(f"Transcription failed: {e}")
            return {
                'text': '',
                'words': [],
                'duration': 0,
                'language': 'en',
                'segments_count': 0,
                'device_used': self.device,
                'transcription_time': 0,
                'error': str(e)
            }
    
    def transcribe_with_timestamps_and_validation(self, audio_path: str) -> Dict:
        """
        NEW: Transcribe audio with enhanced validation to prevent script timing issues
        
        Args:
            audio_path: Path to audio file
            
        Returns:
            Dictionary with transcription and validation info
        """
        try:
            logger.info(f"üé§ Starting VALIDATED transcription on {self.device.upper()}...")
            
            # Get exact audio duration first for validation bounds
            actual_audio_duration = self.get_audio_duration(audio_path)
            
            # Show GPU memory usage if using CUDA
            if self.device == "cuda":
                gpu_memory_before = torch.cuda.memory_allocated(0) / 1024**2
                logger.info(f"GPU Memory before: {gpu_memory_before:.1f}MB")
            
            start_time = time.time()
            
            with self.model_lock:  # Thread-safe model access
                result = self.whisper_model.transcribe(
                    audio_path,
                    word_timestamps=True,
                    verbose=False,
                    language="en"
                )
            
            transcription_time = time.time() - start_time
            
            # Show performance stats
            if self.device == "cuda":
                gpu_memory_after = torch.cuda.memory_allocated(0) / 1024**2
                logger.info(f"GPU Memory after: {gpu_memory_after:.1f}MB")
                logger.info(f"‚ö° GPU Transcription completed in {transcription_time:.2f}s")
            else:
                logger.info(f"üíª CPU Transcription completed in {transcription_time:.2f}s")
            
            words_with_timing = []
            full_text = ""
            discarded_words = 0
            
            for segment in result.get('segments', []):
                if 'words' in segment and segment['words']:
                    for word_data in segment['words']:
                        word_start = word_data.get('start', 0)
                        word_end = word_data.get('end', 0)
                        
                        # VALIDATION: Ensure word timing is within actual audio bounds
                        if word_end <= actual_audio_duration + 0.1:  # Small tolerance for imprecision
                            word_info = {
                                'text': word_data.get('word', '').strip(),
                                'start': word_start,
                                'end': word_end,
                                'confidence': word_data.get('probability', 0.9),
                                'source': 'whisper_validated'  # Mark as validated Whisper word
                            }
                            words_with_timing.append(word_info)
                            full_text += word_info['text'] + " "
                        else:
                            discarded_words += 1
                            logger.debug(f"Discarded Whisper word ending at {word_end:.2f}s (beyond {actual_audio_duration:.2f}s)")
            
            if discarded_words > 0:
                logger.warning(f"üõ°Ô∏è VALIDATION: Discarded {discarded_words} Whisper words extending beyond audio duration")
            
            # Use actual audio duration, not the last word's end time
            total_duration = actual_audio_duration
            
            transcription_result = {
                'text': full_text.strip(),
                'words': words_with_timing,
                'duration': total_duration,
                'actual_audio_duration': actual_audio_duration,  # NEW: Store actual audio duration
                'language': result.get('language', 'en'),
                'segments_count': len(result.get('segments', [])),
                'device_used': self.device,
                'transcription_time': transcription_time,
                'validation_info': {  # NEW: Validation information
                    'total_whisper_words': len(words_with_timing) + discarded_words,
                    'validated_words': len(words_with_timing),
                    'discarded_words': discarded_words,
                    'audio_duration_bound': actual_audio_duration,
                    'validation_tolerance': 0.1
                }
            }
            
            logger.info(f"‚úÖ VALIDATED transcription complete: {len(words_with_timing)} words, {total_duration:.2f}s duration")
            if discarded_words > 0:
                logger.info(f"üõ°Ô∏è Validation prevented {discarded_words} words from extending beyond audio")
            
            return transcription_result
            
        except Exception as e:
            logger.error(f"Validated transcription failed: {e}")
            return {
                'text': '',
                'words': [],
                'duration': 0,
                'actual_audio_duration': 0,
                'language': 'en',
                'segments_count': 0,
                'device_used': self.device,
                'transcription_time': 0,
                'validation_info': {
                    'total_whisper_words': 0,
                    'validated_words': 0,
                    'discarded_words': 0,
                    'audio_duration_bound': 0,
                    'validation_tolerance': 0.1
                },
                'error': str(e)
            }
    
    def validate_audio_file(self, audio_path: str) -> bool:
        """Validate that audio file is readable and has content"""
        try:
            audio_data, sample_rate = sf.read(audio_path)
            
            if len(audio_data) == 0:
                logger.error("Audio file is empty")
                return False
            
            duration = len(audio_data) / sample_rate
            if duration < 0.1:  # Allow very short audio for title
                logger.error(f"Audio file too short: {duration:.2f}s")
                return False
            
            logger.info(f"Audio file validated: {duration:.2f}s, {sample_rate}Hz")
            return True
            
        except Exception as e:
            logger.error(f"Audio validation failed: {e}")
            return False
    
    def create_silence_audio(self, duration: float, sample_rate: int = 44100) -> str:
        """Create EXACT silence audio file for delays and dead air"""
        try:
            # FIXED: Ensure EXACT duration by calculating exact samples
            silence_samples = int(duration * sample_rate)
            silence_data = np.zeros(silence_samples, dtype=np.float32)
            
            silence_path = tempfile.mktemp(suffix='.wav')
            sf.write(silence_path, silence_data, sample_rate)
            
            # Verify created duration
            created_duration = silence_samples / sample_rate
            logger.info(f"Created EXACT silence audio: {created_duration:.3f}s (requested: {duration:.3f}s)")
            return silence_path
            
        except Exception as e:
            logger.error(f"Failed to create silence audio: {e}")
            return None
    
    def combine_audio_files(self, audio_files: List[str], output_path: str = None) -> str:
        """Combine multiple audio files sequentially with EXACT timing"""
        try:
            if not audio_files:
                raise Exception("No audio files provided")
            
            if output_path is None:
                output_path = tempfile.mktemp(suffix='.wav')
            
            # Read all audio files
            combined_data = []
            sample_rate = None
            cumulative_duration = 0.0
            
            for i, audio_file in enumerate(audio_files):
                if audio_file is None:
                    continue
                    
                audio_data, sr = sf.read(audio_file)
                file_duration = len(audio_data) / sr
                
                # Ensure consistent sample rate
                if sample_rate is None:
                    sample_rate = sr
                elif sr != sample_rate:
                    logger.warning(f"Sample rate mismatch: {sr} vs {sample_rate}, resampling may be needed")
                
                combined_data.append(audio_data)
                cumulative_duration += file_duration
                
                logger.info(f"  ‚Ä¢ File {i+1}: {file_duration:.3f}s (cumulative: {cumulative_duration:.3f}s)")
            
            if not combined_data:
                raise Exception("No valid audio data found")
            
            # Concatenate all audio data
            final_audio = np.concatenate(combined_data)
            
            # Write combined audio
            sf.write(output_path, final_audio, sample_rate)
            
            # Verify final duration
            final_duration = len(final_audio) / sample_rate
            logger.info(f"Combined {len(audio_files)} audio files: {final_duration:.3f}s total")
            
            return output_path
            
        except Exception as e:
            logger.error(f"Failed to combine audio files: {e}")
            return audio_files[0] if audio_files else None
    
    def get_device_info(self) -> Dict:
        """Get current device information"""
        info = {"device": self.device}
        
        if self.device == "cuda" and torch.cuda.is_available():
            info.update({
                "gpu_name": torch.cuda.get_device_name(0),
                "gpu_memory_total": f"{torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB",
                "gpu_memory_allocated": f"{torch.cuda.memory_allocated(0) / 1024**2:.1f}MB",
                "cuda_version": torch.version.cuda
            })
        
        return info
    
    def prepare_dual_audio_for_video(self, title_audio_path: str, main_audio_path: str, 
                                   delay_duration: float = 1.0, ending_silence: float = None) -> str:
        """
        FIXED: Prepare combined audio file for video with EXACT timing: title + delay + main + ending silence
        
        Args:
            title_audio_path: Path to title audio
            main_audio_path: Path to main audio
            delay_duration: Delay between title and main (default 1.0s)
            ending_silence: Silence at end for dead air (default 3.5s)
            
        Returns:
            Path to combined audio file with dead air
        """
        try:
            # Use default ending silence if not specified
            if ending_silence is None:
                ending_silence = self.default_ending_silence
            
            logger.info(f"Preparing dual audio for video with EXACT timing + {ending_silence:.1f}s dead air")
            
            # Get exact durations for logging
            title_duration = self.get_audio_duration(title_audio_path)
            main_duration = self.get_audio_duration(main_audio_path)
            
            # Create EXACT silence files
            delay_silence_path = self.create_silence_audio(delay_duration)
            ending_silence_path = self.create_silence_audio(ending_silence)
            
            if delay_silence_path is None or ending_silence_path is None:
                logger.warning("Failed to create silence, using main audio only")
                return main_audio_path
            
            # Combine with EXACT timing: title + delay_silence + main + ending_silence
            audio_files = [title_audio_path, delay_silence_path, main_audio_path, ending_silence_path]
            combined_path = self.combine_audio_files(audio_files)
            
            if combined_path:
                # Verify final timing
                total_duration = self.get_audio_duration(combined_path)
                expected_duration = title_duration + delay_duration + main_duration + ending_silence
                
                logger.info(f"‚úÖ Dual audio prepared for video with EXACT timing:")
                logger.info(f"  ‚Ä¢ Title audio: {title_duration:.3f}s")
                logger.info(f"  ‚Ä¢ Delay: {delay_duration:.3f}s")
                logger.info(f"  ‚Ä¢ Main audio: {main_duration:.3f}s")
                logger.info(f"  ‚Ä¢ Dead air: {ending_silence:.3f}s")
                logger.info(f"  ‚Ä¢ Expected total: {expected_duration:.3f}s")
                logger.info(f"  ‚Ä¢ Actual total: {total_duration:.3f}s")
                
                if abs(total_duration - expected_duration) > 0.1:
                    logger.warning(f"Duration mismatch: expected {expected_duration:.3f}s, got {total_duration:.3f}s")
                
                return combined_path
            else:
                logger.warning("Failed to combine audio, using main audio only")
                return main_audio_path
                
        except Exception as e:
            logger.error(f"Failed to prepare dual audio: {e}")
            return main_audio_path
    
    def create_dead_air_audio(self, base_audio_path: str, dead_air_duration: float = None) -> str:
        """
        Create audio with dead air appended at the end
        
        Args:
            base_audio_path: Path to base audio file
            dead_air_duration: Duration of dead air to append (default 3.5s)
            
        Returns:
            Path to audio file with dead air appended
        """
        try:
            # Use default dead air duration if not specified
            if dead_air_duration is None:
                dead_air_duration = self.default_ending_silence
            
            logger.info(f"Creating audio with {dead_air_duration:.1f}s dead air")
            
            # Create dead air silence
            dead_air_path = self.create_silence_audio(dead_air_duration)
            
            if dead_air_path is None:
                logger.warning("Failed to create dead air, using original audio")
                return base_audio_path
            
            # Combine base audio + dead air
            audio_files = [base_audio_path, dead_air_path]
            combined_path = self.combine_audio_files(audio_files)
            
            if combined_path:
                base_duration = self.get_audio_duration(base_audio_path)
                total_duration = self.get_audio_duration(combined_path)
                
                logger.info(f"‚úÖ Audio with dead air created:")
                logger.info(f"  ‚Ä¢ Original duration: {base_duration:.2f}s")
                logger.info(f"  ‚Ä¢ Dead air: {dead_air_duration:.2f}s")
                logger.info(f"  ‚Ä¢ Total duration: {total_duration:.2f}s")
                
                return combined_path
            else:
                logger.warning("Failed to combine audio with dead air")
                return base_audio_path
                
        except Exception as e:
            logger.error(f"Failed to create dead air audio: {e}")
            return base_audio_path
    
    def analyze_audio_composition(self, title_audio_path: str, main_audio_path: str, 
                                ending_silence: float = None) -> Dict:
        """
        Analyze the composition of a dual audio system including dead air
        
        Args:
            title_audio_path: Path to title audio
            main_audio_path: Path to main audio
            ending_silence: Duration of ending silence (default 3.5s)
            
        Returns:
            Dictionary with detailed composition analysis
        """
        try:
            # Use default ending silence if not specified
            if ending_silence is None:
                ending_silence = self.default_ending_silence
            
            title_duration = self.get_audio_duration(title_audio_path)
            main_duration = self.get_audio_duration(main_audio_path)
            delay_duration = 1.0
            
            # Calculate phase durations
            title_phase_duration = title_duration
            delay_phase_duration = delay_duration
            main_phase_duration = main_duration
            dead_air_duration = ending_silence
            
            # Calculate cumulative timings
            title_end = title_phase_duration
            delay_end = title_end + delay_phase_duration
            main_end = delay_end + main_phase_duration
            total_end = main_end + dead_air_duration
            
            composition = {
                'phases': {
                    'title': {
                        'duration': title_phase_duration,
                        'start': 0.0,
                        'end': title_end,
                        'description': 'Title audio plays, Reddit post displayed'
                    },
                    'delay': {
                        'duration': delay_phase_duration,
                        'start': title_end,
                        'end': delay_end,
                        'description': 'Silence delay, Reddit post still displayed'
                    },
                    'main': {
                        'duration': main_phase_duration,
                        'start': delay_end,
                        'end': main_end,
                        'description': 'Main audio plays, synchronized text displayed'
                    },
                    'dead_air': {
                        'duration': dead_air_duration,
                        'start': main_end,
                        'end': total_end,
                        'description': 'Dead air - last text remains visible, background continues'
                    }
                },
                'totals': {
                    'audio_content_duration': main_end,  # Duration of actual audio content
                    'total_duration': total_end,  # Duration including dead air
                    'dead_air_percentage': (dead_air_duration / total_end) * 100,
                    'active_audio_percentage': (main_end / total_end) * 100
                },
                'reddit_integration': {
                    'reddit_display_duration': delay_end,  # How long Reddit post is shown
                    'text_display_duration': main_phase_duration + dead_air_duration,  # How long text is shown
                    'text_start_time': delay_end  # When text starts appearing
                },
                # NEW: Script validation bounds
                'script_validation_bounds': {
                    'main_audio_end': main_phase_duration,  # End of main audio only
                    'total_audio_end': main_end,  # End of all audio content
                    'dead_air_start': main_end,  # When dead air begins
                    'safe_word_end_limit': main_phase_duration + 0.1  # Safe limit for script words
                }
            }
            
            logger.info(f"üìä Audio composition analysis with script validation bounds:")
            logger.info(f"  ‚Ä¢ Total duration: {total_end:.2f}s")
            logger.info(f"  ‚Ä¢ Audio content: {main_end:.2f}s ({composition['totals']['active_audio_percentage']:.1f}%)")
            logger.info(f"  ‚Ä¢ Dead air: {dead_air_duration:.2f}s ({composition['totals']['dead_air_percentage']:.1f}%)")
            logger.info(f"  üõ°Ô∏è Script word limit: {composition['script_validation_bounds']['safe_word_end_limit']:.2f}s")
            
            return composition
            
        except Exception as e:
            logger.error(f"Failed to analyze audio composition: {e}")
            return {}
    
    def get_dead_air_info(self) -> Dict:
        """
        Get information about dead air configuration
        
        Returns:
            Dictionary with dead air configuration details
        """
        return {
            'default_duration': self.default_ending_silence,
            'purpose': 'Reflection time for viewers - last text remains visible',
            'behavior': 'Background video continues, text stays visible, audio is silent',
            'recommended_range': '2.0 - 5.0 seconds',
            'current_setting': f'{self.default_ending_silence:.1f} seconds',
            'script_safety': 'Script words are validated to not extend into dead air period'
        }
    
    def verify_dead_air_timing(self, prepared_audio_path: str, expected_dead_air_duration: float) -> bool:
        """
        Verify that prepared audio has correct dead air timing
        
        Args:
            prepared_audio_path: Path to prepared audio file
            expected_dead_air_duration: Expected duration of dead air
            
        Returns:
            True if timing is correct
        """
        try:
            # Read the audio file
            audio_data, sample_rate = sf.read(prepared_audio_path)
            total_duration = len(audio_data) / sample_rate
            
            # Check for silence at the end
            dead_air_samples = int(expected_dead_air_duration * sample_rate)
            
            if len(audio_data) < dead_air_samples:
                logger.warning("Audio file too short to contain expected dead air")
                return False
            
            # Check if the last portion is silent (within tolerance)
            end_portion = audio_data[-dead_air_samples:]
            max_amplitude = np.max(np.abs(end_portion))
            
            # Should be very quiet (near silence)
            if max_amplitude > 0.01:  # Tolerance for near-silence
                logger.warning(f"End portion not silent enough: max amplitude {max_amplitude:.4f}")
                return False
            
            logger.info(f"‚úÖ Dead air timing verified: {expected_dead_air_duration:.2f}s of silence at end")
            return True
            
        except Exception as e:
            logger.error(f"Failed to verify dead air timing: {e}")
            return False
    
    def validate_script_words_against_audio(self, words: List[Dict], main_audio_duration: float) -> Tuple[List[Dict], int]:
        """
        NEW: Validate script-matched words against actual audio duration to prevent dead air text issues
        
        Args:
            words: List of word dictionaries from script matching
            main_audio_duration: Duration of main audio content (without dead air)
            
        Returns:
            Tuple of (validated_words, discarded_count)
        """
        if not words:
            return words, 0
        
        validated_words = []
        discarded_words = []
        tolerance = 0.1  # Small tolerance for timing imprecision
        
        logger.info(f"üõ°Ô∏è SCRIPT VALIDATION: Checking {len(words)} words against audio duration {main_audio_duration:.2f}s")
        
        for word in words:
            word_end = word.get('end', 0)
            word_source = word.get('source', 'unknown')
            word_text = word.get('text', '')
            
            # Be especially strict with script-estimated words
            max_allowed_end = main_audio_duration + (tolerance if word_source != 'script_estimated' else 0.0)
            
            if word_end <= max_allowed_end:
                validated_words.append(word)
            else:
                discarded_words.append(word)
                logger.warning(f"üõ°Ô∏è DISCARDED script word: '{word_text}' "
                             f"(ends at {word_end:.2f}s > {max_allowed_end:.2f}s, source: {word_source})")
        
        discarded_count = len(discarded_words)
        
        if discarded_count > 0:
            logger.error(f"üõ°Ô∏è SCRIPT VALIDATION: Discarded {discarded_count} words to prevent dead air text issues!")
            logger.error("These words would have appeared during the 3.5s dead air period.")
            
            # Log details of discarded words for debugging
            for word in discarded_words:
                logger.error(f"  ‚Ä¢ '{word.get('text', '')}' at {word.get('end', 0):.2f}s ({word.get('source', 'unknown')})")
        else:
            logger.info(f"‚úÖ SCRIPT VALIDATION: All {len(validated_words)} words are within audio bounds")
        
        return validated_words, discarded_count
    
    def get_script_validation_info(self) -> Dict:
        """
        NEW: Get information about script validation features
        
        Returns:
            Dictionary with script validation details
        """
        return {
            'validation_enabled': True,
            'purpose': 'Prevent script words from appearing during dead air period',
            'validation_method': 'Check word end times against actual audio duration',
            'tolerance': 0.1,  # seconds
            'strict_sources': ['script_estimated'],
            'protection': 'Automatically discards words extending beyond audio content',
            'dead_air_protection': f'{self.default_ending_silence:.1f}s dead air period protected'
        }